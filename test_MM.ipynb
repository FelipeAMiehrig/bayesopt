{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.quasirandom import SobolEngine\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import hydra\n",
    "import torch\n",
    "import botorch\n",
    "import wandb\n",
    "from botorch.models.transforms import Standardize\n",
    "from botorch.models.transforms.input import Normalize\n",
    "from mgp_models.fully_bayesian import  MGPFullyBayesianSingleTaskGP\n",
    "from mgp_models.fit_fully_bayesian import fit_fully_bayesian_mgp_model_nuts, fit_partially_bayesian_mgp_model\n",
    "from mgp_models.utils import get_candidate_pool, get_test_set, get_acq_values_pool, eval_nll, eval_rmse, convert_bounds\n",
    "from mgp_models.acquisition import BQBCAcquisitionFunction\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Optional\n",
    "\n",
    "from botorch.acquisition.monte_carlo import MCAcquisitionFunction\n",
    "from botorch.acquisition import AnalyticAcquisitionFunction\n",
    "from botorch.models.model import Model\n",
    "from botorch.sampling.base import MCSampler\n",
    "from botorch.sampling.normal import SobolQMCNormalSampler\n",
    "from botorch.utils import t_batch_mode_transform\n",
    "from torch import Tensor\n",
    "import torch\n",
    "\n",
    "from botorch.acquisition import AnalyticAcquisitionFunction\n",
    "from mgp_models.fully_bayesian import  MGPFullyBayesianSingleTaskGP\n",
    "from botorch.posteriors.fully_bayesian import GaussianMixturePosterior, MCMC_DIM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkwargs = {\n",
    "\"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "\"dtype\": torch.double,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM = 6\n",
    "BOUNDS = [[0,1], [0,1], [0,1],[0,1],[0,1],[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_function = botorch.test_functions.Hartmann(noise_std=0.13784048).to(**tkwargs)\n",
    "bounds = synthetic_function.bounds\n",
    "    #print(bounds)\n",
    "X = SobolEngine(dimension=6, scramble=True, seed=0).draw(30).to(**tkwargs)\n",
    "    #print(X)\n",
    "X_scaled = convert_bounds(X, BOUNDS, DIM)\n",
    "Y = synthetic_function(X_scaled).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = Y  # Flip the sign since we want to minimize f(x)\n",
    "gp = MGPFullyBayesianSingleTaskGP(\n",
    "    train_X=X, \n",
    "    train_Y=train_Y, \n",
    "    #train_Yvar=torch.full_like(train_Y, 1e-6),\n",
    "    #input_transform=Normalize(d=cfg.functions.dim, bounds=bountensor_scaledds),\n",
    "    outcome_transform=Standardize(m=1)\n",
    ")\n",
    "ll = fit_partially_bayesian_mgp_model(gp,\n",
    "                                        20,\n",
    "                                        0.1,\n",
    "                                        300,\n",
    "                                        print_iter=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9966],\n",
       "         [0.9999],\n",
       "         [0.9844],\n",
       "         [0.9714],\n",
       "         [0.9804],\n",
       "         [0.9984],\n",
       "         [0.9901],\n",
       "         [0.9803],\n",
       "         [0.9869],\n",
       "         [0.9853]],\n",
       "\n",
       "        [[0.9915],\n",
       "         [0.9995],\n",
       "         [0.9664],\n",
       "         [0.9460],\n",
       "         [0.9756],\n",
       "         [0.9962],\n",
       "         [0.9678],\n",
       "         [0.9390],\n",
       "         [0.9670],\n",
       "         [0.9761]],\n",
       "\n",
       "        [[0.9962],\n",
       "         [0.9999],\n",
       "         [0.9828],\n",
       "         [0.9685],\n",
       "         [0.9784],\n",
       "         [0.9982],\n",
       "         [0.9891],\n",
       "         [0.9783],\n",
       "         [0.9855],\n",
       "         [0.9838]],\n",
       "\n",
       "        [[0.9863],\n",
       "         [0.9995],\n",
       "         [0.9432],\n",
       "         [0.9020],\n",
       "         [0.9351],\n",
       "         [0.9880],\n",
       "         [0.9668],\n",
       "         [0.9319],\n",
       "         [0.9518],\n",
       "         [0.9454]],\n",
       "\n",
       "        [[0.9869],\n",
       "         [0.9991],\n",
       "         [0.9453],\n",
       "         [0.9049],\n",
       "         [0.9535],\n",
       "         [0.9944],\n",
       "         [0.9664],\n",
       "         [0.9328],\n",
       "         [0.9508],\n",
       "         [0.9497]],\n",
       "\n",
       "        [[0.9889],\n",
       "         [0.9997],\n",
       "         [0.9711],\n",
       "         [0.9570],\n",
       "         [0.9718],\n",
       "         [0.9967],\n",
       "         [0.9867],\n",
       "         [0.9678],\n",
       "         [0.9611],\n",
       "         [0.9808]],\n",
       "\n",
       "        [[0.9947],\n",
       "         [0.9997],\n",
       "         [0.9754],\n",
       "         [0.9695],\n",
       "         [0.9683],\n",
       "         [0.9946],\n",
       "         [0.9865],\n",
       "         [0.9852],\n",
       "         [0.9813],\n",
       "         [0.9832]],\n",
       "\n",
       "        [[0.9847],\n",
       "         [0.9995],\n",
       "         [0.9543],\n",
       "         [0.9103],\n",
       "         [0.9545],\n",
       "         [0.9941],\n",
       "         [0.9755],\n",
       "         [0.9051],\n",
       "         [0.9795],\n",
       "         [0.9650]],\n",
       "\n",
       "        [[0.9879],\n",
       "         [0.9991],\n",
       "         [0.9613],\n",
       "         [0.9043],\n",
       "         [0.9193],\n",
       "         [0.9942],\n",
       "         [0.9520],\n",
       "         [0.9474],\n",
       "         [0.9558],\n",
       "         [0.9516]],\n",
       "\n",
       "        [[0.9936],\n",
       "         [0.9996],\n",
       "         [0.9728],\n",
       "         [0.9414],\n",
       "         [0.9514],\n",
       "         [0.9969],\n",
       "         [0.9714],\n",
       "         [0.9643],\n",
       "         [0.9748],\n",
       "         [0.9727]],\n",
       "\n",
       "        [[0.9863],\n",
       "         [0.9995],\n",
       "         [0.9432],\n",
       "         [0.9021],\n",
       "         [0.9351],\n",
       "         [0.9940],\n",
       "         [0.9668],\n",
       "         [0.9320],\n",
       "         [0.9518],\n",
       "         [0.9454]],\n",
       "\n",
       "        [[0.9960],\n",
       "         [0.9998],\n",
       "         [0.9819],\n",
       "         [0.9668],\n",
       "         [0.9773],\n",
       "         [0.9981],\n",
       "         [0.9885],\n",
       "         [0.9771],\n",
       "         [0.9848],\n",
       "         [0.9830]],\n",
       "\n",
       "        [[0.9900],\n",
       "         [0.9994],\n",
       "         [0.9822],\n",
       "         [0.9591],\n",
       "         [0.9415],\n",
       "         [0.9958],\n",
       "         [0.9874],\n",
       "         [0.9555],\n",
       "         [0.9766],\n",
       "         [0.9535]],\n",
       "\n",
       "        [[0.9869],\n",
       "         [0.9990],\n",
       "         [0.9454],\n",
       "         [0.9048],\n",
       "         [0.9533],\n",
       "         [0.9944],\n",
       "         [0.9664],\n",
       "         [0.9323],\n",
       "         [0.9507],\n",
       "         [0.9498]],\n",
       "\n",
       "        [[0.9966],\n",
       "         [0.9999],\n",
       "         [0.9844],\n",
       "         [0.9714],\n",
       "         [0.9804],\n",
       "         [0.9984],\n",
       "         [0.9901],\n",
       "         [0.9803],\n",
       "         [0.9869],\n",
       "         [0.9853]],\n",
       "\n",
       "        [[0.9963],\n",
       "         [0.9999],\n",
       "         [0.9832],\n",
       "         [0.9692],\n",
       "         [0.9789],\n",
       "         [0.9983],\n",
       "         [0.9894],\n",
       "         [0.9787],\n",
       "         [0.9859],\n",
       "         [0.9842]],\n",
       "\n",
       "        [[0.9934],\n",
       "         [0.9997],\n",
       "         [0.9703],\n",
       "         [0.9461],\n",
       "         [0.9634],\n",
       "         [0.9970],\n",
       "         [0.9815],\n",
       "         [0.9628],\n",
       "         [0.9750],\n",
       "         [0.9721]],\n",
       "\n",
       "        [[0.9933],\n",
       "         [0.9995],\n",
       "         [0.9705],\n",
       "         [0.9393],\n",
       "         [0.9196],\n",
       "         [0.9966],\n",
       "         [0.9597],\n",
       "         [0.9599],\n",
       "         [0.9595],\n",
       "         [0.9726]],\n",
       "\n",
       "        [[0.9868],\n",
       "         [0.9995],\n",
       "         [0.9450],\n",
       "         [0.9048],\n",
       "         [0.9368],\n",
       "         [0.9942],\n",
       "         [0.9677],\n",
       "         [0.9339],\n",
       "         [0.9533],\n",
       "         [0.9472]],\n",
       "\n",
       "        [[0.9894],\n",
       "         [0.9992],\n",
       "         [0.9508],\n",
       "         [0.9191],\n",
       "         [0.9349],\n",
       "         [0.9895],\n",
       "         [0.9749],\n",
       "         [0.9558],\n",
       "         [0.9758],\n",
       "         [0.9553]]], device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<RsubBackward1>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acq_function = SALHRMMAcquisitionFunction(gp, ll=ll)\n",
    "\n",
    "poolU = get_candidate_pool(dim=DIM, bounds=BOUNDS, size=10).to(**tkwargs)\n",
    "acq_values = acq_function(poolU)\n",
    "acq_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SALHRMMAcquisitionFunction(AnalyticAcquisitionFunction):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: MGPFullyBayesianSingleTaskGP,\n",
    "        maximize: bool = True,\n",
    "        ll: Optional[Tensor] = None\n",
    "    ) -> None:\n",
    "        # we use the AcquisitionFunction constructor, since that of\n",
    "        # AnalyticAcquisitionFunction performs some validity checks that we don't want here\n",
    "        super(AnalyticAcquisitionFunction, self).__init__(model)\n",
    "        self.maximize = maximize\n",
    "        self.ll = ll\n",
    "\n",
    "    def forward(self, X: Tensor) -> Tensor:\n",
    "\n",
    "\n",
    "        posterior = self.model.posterior(X, ll= self.ll)\n",
    "        n_models = posterior._mean.shape[MCMC_DIM]\n",
    "        mean_minus_mgpmean = posterior._mean - posterior.mixture_mean.repeat(n_models,1,1)\n",
    "        BQBC = mean_minus_mgpmean.pow(2).sum(dim=MCMC_DIM)\n",
    "        var = posterior._variance.sum(dim=MCMC_DIM)\n",
    "        mixture_variance = BQBC + var\n",
    "        sigma_1 = mixture_variance.repeat(n_models,1,1)\n",
    "        mixture_mean = posterior._mean.sum(dim=MCMC_DIM)\n",
    "        mu_1 = mixture_mean.repeat(n_models,1,1)\n",
    "        sigma_2 = posterior.variance\n",
    "        mu_2 = posterior.mean\n",
    "        up = 2*torch.sqrt(sigma_1)*torch.sqrt(sigma_2)\n",
    "        down = sigma_1+sigma_2\n",
    "        to_sqrt = up.div(down)\n",
    "        sqrted = torch.sqrt(to_sqrt)\n",
    "        mean_up = mu_1 - mu_2\n",
    "        mean_up = mean_up.pow(2)\n",
    "        exped = torch.exp(-0.25*mean_up.div(down))\n",
    "        right = sqrted* exped\n",
    "        hellinger = 1 - right\n",
    "        return hellinger.mul(posterior.shaped_weights).sum(dim=MCMC_DIM)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bo-cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
